{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":125192,"databundleVersionId":15408205,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"```load data```","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom xgboost import XGBClassifier\n\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s6e2/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s6e2/test.csv\")\n\nprint(train_df.shape, test_df.shape)\n# train_df.head(10)\n# train_df.columns\n# test_df.columns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Separate Features & Target```","metadata":{}},{"cell_type":"code","source":"ID_COL = \"id\"\nTARGET_COL = \"Heart Disease\"   \ntrain_df.drop('id', axis=1, inplace=True) # id is not used for model training and prediction\nX = train_df.drop(columns=[TARGET_COL]).copy()\n\ny_raw = train_df[TARGET_COL].copy()\n\n# Convert target to 0/1\n# Absence -> 0, Presence -> 1\ny = y_raw.map({\"Absence\": 0, \"Presence\": 1}).astype(int)\n\nX_test = test_df\n\n# Drop ID column\nif ID_COL in X.columns:\n    X = X.drop(columns=[ID_COL])\nif ID_COL in X_test.columns:\n    X_test = X_test.drop(columns=[ID_COL])\n\nprint(\"X shape:\", X.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Target distribution:\")\nprint(y.value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Feature Engineering```","metadata":{}},{"cell_type":"code","source":"# STEP 1: Age × Max HR\nX[\"Age_x_MaxHR\"] = X[\"Age\"] * X[\"Max HR\"]\nX_test[\"Age_x_MaxHR\"] = X_test[\"Age\"] * X_test[\"Max HR\"]\n\n# STEP 2: ST depression × Exercise angina\nX[\"ST_x_Angina\"] = X[\"ST depression\"] * X[\"Exercise angina\"]\nX_test[\"ST_x_Angina\"] = X_test[\"ST depression\"] * X_test[\"Exercise angina\"]\n\n# STEP 3: High blood pressure flag (BP ≥ 140)\nX[\"High_BP\"] = (X[\"BP\"] >= 140).astype(int)\nX_test[\"High_BP\"] = (X_test[\"BP\"] >= 140).astype(int)\n\n# STEP 4: Cholesterol risk bin (0=normal, 1=borderline, 2=high)\nX[\"Chol_bin\"] = pd.cut(X[\"Cholesterol\"], bins=[0, 200, 240, 2000], labels=[0, 1, 2]).astype(int)\nX_test[\"Chol_bin\"] = pd.cut(X_test[\"Cholesterol\"], bins=[0, 200, 240, 2000], labels=[0, 1, 2]).astype(int)\n\n# STEP 5: Age risk bucket\nX[\"Age_bin\"] = pd.cut(\n    X[\"Age\"],\n    bins=[0, 40, 50, 60, 70, 120],\n    labels=[0, 1, 2, 3, 4]\n).astype(int)\n\nX_test[\"Age_bin\"] = pd.cut(\n    X_test[\"Age\"],\n    bins=[0, 40, 50, 60, 70, 120],\n    labels=[0, 1, 2, 3, 4]\n).astype(int)\n\n# STEP 6: Low maximum heart rate flag\nX[\"Low_MaxHR\"] = (X[\"Max HR\"] < 120).astype(int)\nX_test[\"Low_MaxHR\"] = (X_test[\"Max HR\"] < 120).astype(int)\n\n# STEP 7: ST depression severity bucket\nX[\"ST_bin\"] = pd.cut(\n    X[\"ST depression\"],\n    bins=[-1, 0.5, 1.5, 10],\n    labels=[0, 1, 2]\n).astype(int)\n\nX_test[\"ST_bin\"] = pd.cut(\n    X_test[\"ST depression\"],\n    bins=[-1, 0.5, 1.5, 10],\n    labels=[0, 1, 2]\n).astype(int)\n\n\n# STEP 8: Simple risk score\nX[\"Risk_score\"] = (\n    X[\"High_BP\"]\n    + X[\"Chol_bin\"]\n    + X[\"Exercise angina\"]\n    + X[\"Age_bin\"]\n)\n\nX_test[\"Risk_score\"] = (\n    X_test[\"High_BP\"]\n    + X_test[\"Chol_bin\"]\n    + X_test[\"Exercise angina\"]\n    + X_test[\"Age_bin\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"neg = (y == 0).sum()\npos = (y == 1).sum()\nscale_pos_weight = neg / pos\n\nprint(\"scale_pos_weight:\", scale_pos_weight)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Build a pipeline```\n\n\nRandom Forest Classifier","metadata":{}},{"cell_type":"code","source":"# pipe = Pipeline(steps=[\n#     (\"imputer\", SimpleImputer(strategy=\"median\")),\n#     (\"model\", RandomForestClassifier(\n#         n_estimators=300,\n#         max_depth=12,\n#         min_samples_leaf=10,\n#         random_state=42,\n#         n_jobs=-1\n#     ))\n# ])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Build a pipeline```\n\n\nExtra Trees Classifier","metadata":{}},{"cell_type":"code","source":"# pipe = Pipeline(steps=[\n#     (\"imputer\", SimpleImputer(strategy=\"median\")),\n#     (\"model\", ExtraTreesClassifier(\n#         n_estimators=800,\n#         max_depth=None,\n#         min_samples_leaf=5,\n#         max_features=\"sqrt\",\n#         class_weight=\"balanced\",\n#         random_state=42,\n#         n_jobs=-1\n#     ))\n# ])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```identify columns```","metadata":{}},{"cell_type":"code","source":"categorical_cols = [\n    \"Sex\",\n    \"Chest pain type\",\n    \"FBS over 120\",\n    \"EKG results\",\n    \"Exercise angina\",\n    \"Slope of ST\",\n    \"Number of vessels fluro\",\n    \"Thallium\"\n]\n\nnumerical_cols = [\n    \"Age\",\n    \"BP\",\n    \"Cholesterol\",\n    \"Max HR\",\n    \"ST depression\"\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```build a pipeline```\nGradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"# pipe = Pipeline(steps=[\n#     (\"imputer\", SimpleImputer(strategy=\"median\")),\n#     (\"model\", GradientBoostingClassifier(\n#         n_estimators=600,\n#         learning_rate=0.05,\n#         max_depth=3,\n#         subsample=0.8,\n#         random_state=42\n#     ))\n# ])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```XGBClassifier```","metadata":{}},{"cell_type":"code","source":"def make_xgb(seed: int) -> XGBClassifier:\n    return XGBClassifier(\n        n_estimators=4000,\n        learning_rate=0.03,\n\n        max_depth=6,\n        min_child_weight=1,\n\n        subsample=0.85,\n        colsample_bytree=0.85,\n\n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n\n        scale_pos_weight=scale_pos_weight,\n        # early_stopping_rounds=150,\n\n        objective=\"binary:logistic\",\n        eval_metric=\"error\",\n\n        tree_method=\"hist\",\n        random_state=seed,\n        n_jobs=-1\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```define model: RF```","metadata":{}},{"cell_type":"code","source":"# def make_rf(seed: int) -> RandomForestClassifier:\n#     return RandomForestClassifier(\n#         n_estimators=600,\n#         max_depth=14,\n#         min_samples_leaf=8,\n#         max_features=\"sqrt\",\n#         random_state=seed,\n#         n_jobs=-1\n#     )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```define model: ET```","metadata":{}},{"cell_type":"code","source":"# def make_et(seed: int) -> ExtraTreesClassifier:\n#     return ExtraTreesClassifier(\n#         n_estimators=1200,\n#         max_depth=None,\n#         min_samples_leaf=2,\n#         max_features=0.5,\n#         bootstrap=False,\n#         random_state=seed,\n#         n_jobs=-1\n#     )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```build a pipeline```\nlogistic regression","metadata":{}},{"cell_type":"code","source":"# preprocessor = ColumnTransformer(\n#     transformers=[\n#         (\"num\", StandardScaler(), numerical_cols),\n#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), categorical_cols)\n#     ]\n# )\n\n# pipe = Pipeline(steps=[\n#     (\"preprocess\", preprocessor),\n#     (\"model\", LogisticRegression(\n#         C=15,\n#         max_iter=4000,\n#         solver=\"saga\",\n#         l1_ratio=0.2,\n#         penalty=\"elasticnet\",\n#         class_weight=\"balanced\"\n#     ))\n# ])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train ONE final model on full data (no CV)\nmodel = make_xgb(seed=999)\nmodel.fit(X, y)\n\nimportance = pd.Series(\n    model.feature_importances_,\n    index=X.columns\n).sort_values(ascending=False)\n\nimportance.head(15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"importance.head(50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\noof_et = np.zeros(len(train_df))\noof_xgb = np.zeros(len(train_df))\n\ntest_et  = np.zeros(len(test_df))\ntest_xgb = np.zeros(len(test_df))\n\nbest_iters = []\n\nfor fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n    # X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n    # X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n\n    # et = make_et(seed=100 + fold)\n    # et.fit(X_tr, y_tr)\n\n    # et_va_prob = et.predict_proba(X_va)[:, 1]\n    # oof_et[va_idx] = et_va_prob\n\n    # test_et += et.predict_proba(X_test)[:, 1] / skf.n_splits\n    # et_auc  = roc_auc_score(y_va, et_va_prob)\n    # print(f\"Fold {fold} | ET AUC: {et_auc:.6f}\")\n    \n\n\n    \n    xgb = make_xgb(seed=200 + fold)\n    xgb.fit(\n        X_tr, y_tr,\n        eval_set=[(X_va, y_va)],\n        verbose=False\n    )\n\n    best_iters.append(xgb.best_iteration)\n\n    xgb_va_prob = xgb.predict_proba(X_va)[:, 1]\n    oof_xgb[va_idx] = xgb_va_prob\n\n    test_xgb += xgb.predict_proba(X_test)[:, 1] / skf.n_splits\n\n    xgb_auc = roc_auc_score(y_va, xgb_va_prob)\n    print(f\"Fold {fold} | XGB AUC: {xgb_auc:.6f} | XGB best_iter: {xgb.best_iteration}\")\n\nprint(\"\\nMean XGB best_iteration:\", int(np.mean(best_iters)))\nprint(\"OOF ET AUC :\", roc_auc_score(y, oof_et))\nprint(\"OOF XGB AUC:\", roc_auc_score(y, oof_xgb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# oof = np.zeros(len(train_df))\n# test_preds = np.zeros(len(test_df))\n\n# for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n#     X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n#     X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n\n#     pipe.fit(X_tr, y_tr)\n\n#     va_pred = pipe.predict_proba(X_va)[:, 1]\n#     oof[va_idx] = va_pred\n\n#     fold_auc = roc_auc_score(y_va, va_pred)\n#     print(f\"Fold {fold} AUC: {fold_auc:.6f}\")\n\n#     test_preds += pipe.predict_proba(X_test)[:, 1] / skf.n_splits\n\n# print(f\"\\nOverall OOF AUC: {roc_auc_score(y, oof):.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Find optimal bending weight```","metadata":{}},{"cell_type":"code","source":"weights = np.arange(0.0, 1.01, 0.05)\n\nbest_w = {\"auc\": -1.0, \"weight_xgb\": 1.0}\n\nfor w in weights:\n    oof_blend = w * oof_xgb + (1.0 - w) * oof_et\n    auc = roc_auc_score(y, oof_blend)\n\n    if auc > best_w[\"auc\"]:\n        best_w[\"auc\"] = auc\n        best_w[\"weight_xgb\"] = w\n\nprint(\"\\nBest blend by AUC (coarse):\", best_w)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```find AUC weight```","metadata":{}},{"cell_type":"code","source":"w0 = best_w[\"weight_xgb\"]\n\nw_start = max(0.0, w0 - 0.10)\nw_end   = min(1.0, w0 + 0.10)\n\nfine_weights = np.arange(w_start, w_end + 1e-9, 0.01)\n\nbest_w_fine = {\"auc\": -1.0, \"weight_xgb\": w0}\n\nfor w in fine_weights:\n    oof_blend = w * oof_xgb + (1.0 - w) * oof_et\n    auc = roc_auc_score(y, oof_blend)\n\n    if auc > best_w_fine[\"auc\"]:\n        best_w_fine[\"auc\"] = auc\n        best_w_fine[\"weight_xgb\"] = w\n\nprint(\"Best blend by AUC (fine):\", best_w_fine)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# thresholds = np.arange(0.10, 0.90, 0.01)\n\n# # ---- Coarse weight search\n# weights = np.arange(0.0, 1.01, 0.05)\n\n# best = {\"acc\": 0.0, \"weight_xgb\": 0.5, \"threshold\": 0.5}\n\n# for w in weights:\n#     oof_ens = w * oof_xgb + (1.0 - w) * oof_et\n\n#     for t in thresholds:\n#         acc = accuracy_score(y, (oof_ens >= t).astype(int))\n#         if acc > best[\"acc\"]:\n#             best.update({\"acc\": acc, \"weight_xgb\": w, \"threshold\": t})\n\n# print(\"\\nBest (coarse) ->\", best)\n\n# # ---- Fine weight search around best\n# w0 = best[\"weight_xgb\"]\n# w_start = max(0.0, w0 - 0.05)\n# w_end   = min(1.0, w0 + 0.05)\n\n# fine_weights = np.arange(w_start, w_end + 1e-9, 0.01)\n\n# best_fine = best.copy()\n\n# for w in fine_weights:\n#     oof_ens = w * oof_xgb + (1.0 - w) * oof_et\n\n#     for t in thresholds:\n#         acc = accuracy_score(y, (oof_ens >= t).astype(int))\n#         if acc > best_fine[\"acc\"]:\n#             best_fine.update({\"acc\": acc, \"weight_xgb\": w, \"threshold\": t})\n\n# print(\"Best (fine)  ->\", best_fine)\n\n# # Final ensemble settings\n# w_best = best_fine[\"weight_xgb\"]\n# t_best = best_fine[\"threshold\"]\n\n# oof_ens_final = w_best * oof_xgb + (1.0 - w_best) * oof_et\n# print(\"\\nFinal ensemble OOF AUC:\", roc_auc_score(y, oof_ens_final))\n# print(\"Final ensemble CV accuracy:\", accuracy_score(y, (oof_ens_final >= t_best).astype(int)))\n# print(\"Final weight_xgb:\", w_best, \"| weight_et:\", 1.0 - w_best, \"| threshold:\", t_best)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Find best threshold```","metadata":{}},{"cell_type":"code","source":"w_best = best_w_fine[\"weight_xgb\"]\noof_final = w_best * oof_xgb + (1.0 - w_best) * oof_et\n\nthresholds = np.arange(0.10, 0.90, 0.01)\n\nbest_t = {\"acc\": 0.0, \"threshold\": 0.5}\n\nfor t in thresholds:\n    acc = accuracy_score(y, (oof_final >= t).astype(int))\n    if acc > best_t[\"acc\"]:\n        best_t[\"acc\"] = acc\n        best_t[\"threshold\"] = t\n\nprint(\"\\nFinal blend OOF AUC:\", roc_auc_score(y, oof_final))\nprint(\"Best CV accuracy:\", best_t[\"acc\"])\nprint(\"Best threshold:\", best_t[\"threshold\"])\nprint(\"Final weight_xgb:\", w_best, \"| weight_et:\", 1.0 - w_best)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```create submission```","metadata":{}},{"cell_type":"code","source":"test_final = w_best * test_xgb + (1.0 - w_best) * test_et\ntest_preds_binary = (test_final >= best_t[\"threshold\"]).astype(int)\n\nif os.path.exists(\"submission.csv\"):\n    os.remove(\"submission.csv\")\n\nsubmission = pd.DataFrame({\n    \"id\": test_df[ID_COL],\n    \"Heart Disease\": test_preds_binary\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved new submission.csv\")\nsubmission.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":125192,"databundleVersionId":15408205,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"```load data```","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport warnings\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom xgboost import XGBClassifier\nfrom scipy.stats import rankdata\nfrom catboost import CatBoostClassifier\n\n\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s6e2/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s6e2/test.csv\")\n\nprint(train_df.shape, test_df.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\ntry:\n    import torch\n    USE_GPU = torch.cuda.is_available()\nexcept Exception:\n    USE_GPU = False\n\nprint(f\"Hardware: {'GPU' if USE_GPU else 'CPU'}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Separate Features & Target```","metadata":{}},{"cell_type":"code","source":"ID_COL = \"id\"\nTARGET_COL = \"Heart Disease\"   \ntrain_df.drop('id', axis=1, inplace=True) # id is not used for model training and prediction\nX = train_df.drop(columns=[TARGET_COL]).copy()\n\ny_raw = train_df[TARGET_COL].copy()\n\n# Convert target to 0/1\n# Absence -> 0, Presence -> 1\ny = y_raw.map({\"Absence\": 0, \"Presence\": 1}).astype(int)\n\nX_test = test_df\n\n# Drop ID column\nif ID_COL in X.columns:\n    X = X.drop(columns=[ID_COL])\nif ID_COL in X_test.columns:\n    X_test = X_test.drop(columns=[ID_COL])\n\nprint(\"X shape:\", X.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Target distribution:\")\nprint(y.value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Identify Column```","metadata":{}},{"cell_type":"code","source":"cat_cols = [\n    \"Sex\",\n    \"Chest pain type\",\n    \"FBS over 120\",\n    \"EKG results\",\n    \"Exercise angina\",\n    \"Slope of ST\",\n    \"Number of vessels fluro\",\n    \"Thallium\"\n]\n\nnum_cols = [\n    \"Age\",\n    \"BP\",\n    \"Cholesterol\",\n    \"Max HR\",\n    \"ST depression\"\n]\nextra_cat_cols = [\"Chol_bin\", \"Age_bin\", \"ST_bin\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Frequency Encoding```","metadata":{}},{"cell_type":"code","source":"def make_freq_features(df_train, df_test, cols):\n    df_all = pd.concat([df_train[cols], df_test[cols]], axis=0, ignore_index=True)\n    tr_out = pd.DataFrame(index=df_train.index)\n    te_out = pd.DataFrame(index=df_test.index)\n\n    for c in cols:\n        freqs = df_all[c].value_counts(normalize=True)\n        tr_out[f\"{c}_freq\"] = df_train[c].map(freqs).astype(np.float32)\n        te_out[f\"{c}_freq\"] = df_test[c].map(freqs).astype(np.float32)\n\n    return tr_out, te_out\n\ntrain_freq, test_freq = make_freq_features(train_df, test_df, cat_cols + num_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```K-fold target mean encoding```","metadata":{}},{"cell_type":"code","source":"def make_target_mean_features(df_train, y, df_test, cols, n_splits=5, seed=42, alpha=50):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\n    tr_out = pd.DataFrame(index=df_train.index)\n    te_out = pd.DataFrame(index=df_test.index)\n\n    global_mean = float(y.mean())\n\n    for c in cols:\n        tr_feat = pd.Series(index=df_train.index, dtype=np.float32)\n\n        for tr_idx, va_idx in skf.split(df_train, y):\n            tr_part = df_train.iloc[tr_idx]\n            y_part = y.iloc[tr_idx]\n\n            stats = (\n                pd.DataFrame({c: tr_part[c].values, \"y\": y_part.values})\n                .groupby(c)[\"y\"]\n                .agg([\"mean\", \"count\"])\n            )\n\n            smooth = (stats[\"mean\"] * stats[\"count\"] + global_mean * alpha) / (stats[\"count\"] + alpha)\n            tr_feat.iloc[va_idx] = df_train.iloc[va_idx][c].map(smooth)\n\n        full_stats = (\n            pd.DataFrame({c: df_train[c].values, \"y\": y.values})\n            .groupby(c)[\"y\"]\n            .agg([\"mean\", \"count\"])\n        )\n\n        full_smooth = (full_stats[\"mean\"] * full_stats[\"count\"] + global_mean * alpha) / (full_stats[\"count\"] + alpha)\n\n        tr_out[f\"{c}_te\"] = tr_feat.fillna(global_mean).astype(np.float32)\n        te_out[f\"{c}_te\"] = df_test[c].map(full_smooth).fillna(global_mean).astype(np.float32)\n\n    return tr_out, te_out\n\ntrain_te, test_te = make_target_mean_features(train_df, y, test_df, cat_cols, n_splits=5, seed=42, alpha=50)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Build train-test metrics```","metadata":{}},{"cell_type":"code","source":"X = pd.concat(\n    [train_df[cat_cols + num_cols], train_freq, train_te],\n    axis=1\n)\n\nX_test = pd.concat(\n    [test_df[cat_cols + num_cols], test_freq, test_te],\n    axis=1\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Feature Engineering```","metadata":{}},{"cell_type":"code","source":"# STEP 1: Age × Max HR\nX[\"Age_x_MaxHR\"] = X[\"Age\"] * X[\"Max HR\"]\nX_test[\"Age_x_MaxHR\"] = X_test[\"Age\"] * X_test[\"Max HR\"]\n\n# STEP 2: ST depression × Exercise angina\nX[\"ST_x_Angina\"] = X[\"ST depression\"] * X[\"Exercise angina\"]\nX_test[\"ST_x_Angina\"] = X_test[\"ST depression\"] * X_test[\"Exercise angina\"]\n\n# STEP 3: High blood pressure flag (BP ≥ 140)\nX[\"High_BP\"] = (X[\"BP\"] >= 140).astype(int)\nX_test[\"High_BP\"] = (X_test[\"BP\"] >= 140).astype(int)\n\n# STEP 4: Cholesterol risk bin (0=normal, 1=borderline, 2=high)\nX[\"Chol_bin\"] = pd.cut(X[\"Cholesterol\"], bins=[0, 200, 240, 2000], labels=[0, 1, 2]).astype(int)\nX_test[\"Chol_bin\"] = pd.cut(X_test[\"Cholesterol\"], bins=[0, 200, 240, 2000], labels=[0, 1, 2]).astype(int)\n\n# STEP 5: Age risk bucket\nX[\"Age_bin\"] = pd.cut(\n    X[\"Age\"],\n    bins=[0, 40, 50, 60, 70, 120],\n    labels=[0, 1, 2, 3, 4]\n).astype(int)\n\nX_test[\"Age_bin\"] = pd.cut(\n    X_test[\"Age\"],\n    bins=[0, 40, 50, 60, 70, 120],\n    labels=[0, 1, 2, 3, 4]\n).astype(int)\n\n# STEP 6: Low maximum heart rate flag\nX[\"Low_MaxHR\"] = (X[\"Max HR\"] < 120).astype(int)\nX_test[\"Low_MaxHR\"] = (X_test[\"Max HR\"] < 120).astype(int)\n\n# STEP 7: ST depression severity bucket\nX[\"ST_bin\"] = pd.cut(\n    X[\"ST depression\"],\n    bins=[-1, 0.5, 1.5, 10],\n    labels=[0, 1, 2]\n).astype(int)\n\nX_test[\"ST_bin\"] = pd.cut(\n    X_test[\"ST depression\"],\n    bins=[-1, 0.5, 1.5, 10],\n    labels=[0, 1, 2]\n).astype(int)\n\n\n# STEP 8: Simple risk score\nX[\"Risk_score\"] = (\n    X[\"High_BP\"]\n    + X[\"Chol_bin\"]\n    + X[\"Exercise angina\"]\n    + X[\"Age_bin\"]\n)\n\nX_test[\"Risk_score\"] = (\n    X_test[\"High_BP\"]\n    + X_test[\"Chol_bin\"]\n    + X_test[\"Exercise angina\"]\n    + X_test[\"Age_bin\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_cat_cols = cat_cols + extra_cat_cols\n\ncat_features = [X.columns.get_loc(c) for c in all_cat_cols]\n\nprint(\"X_train shape:\", X.shape, \"| X_test shape:\", X_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"CatBoost categorical columns:\")\n# for idx in cat_features:\n#     print(idx, X.columns[idx])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"neg = (y == 0).sum()\npos = (y == 1).sum()\nscale_pos_weight = neg / pos\n\nprint(\"scale_pos_weight:\", scale_pos_weight)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```XGBClassifier```","metadata":{}},{"cell_type":"code","source":"def make_xgb(seed: int) -> XGBClassifier:\n    return XGBClassifier(\n        n_estimators=4000,\n        learning_rate=0.03,\n        \n        max_depth=6,\n        min_child_weight=3,\n        \n        subsample=0.85,\n        colsample_bytree=0.85,\n        \n        scale_pos_weight=scale_pos_weight,\n        early_stopping_rounds=150,\n        \n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n        objective=\"binary:logistic\",\n        eval_metric=\"error\",\n        \n        tree_method=\"hist\",\n        random_state=seed,\n        n_jobs=-1\n    )\n\ncat_params = {\n    \"iterations\": 8000,\n    \"learning_rate\": 0.03,\n    \"depth\": 6,\n    \"loss_function\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"auto_class_weights\": \"Balanced\",\n    \"early_stopping_rounds\": 200,\n    \"task_type\": \"GPU\" if USE_GPU else \"CPU\",\n    \"logging_level\": \"Silent\"\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Cross-validation and seeds```","metadata":{}},{"cell_type":"code","source":"# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nxgb_seeds = [42, 202, 777]\ncat_seeds = [42, 202, 777, 1001, 2023]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Train multi-seed XGBoost (OOF + test probs)```","metadata":{}},{"cell_type":"code","source":"oof_xgb = np.zeros(len(train_df), dtype=np.float32)\ntest_xgb = np.zeros(len(test_df), dtype=np.float32)\nxgb_oof_aucs = []\n\nfor s in xgb_seeds:\n    oof_s = np.zeros(len(train_df), dtype=np.float32)\n    test_s = np.zeros(len(test_df), dtype=np.float32)\n\n    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n        X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n        X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n\n        model = make_xgb(seed=s + fold)\n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            verbose=False\n        )\n\n        va_pred = model.predict_proba(X_va)[:, 1]\n        oof_s[va_idx] = va_pred\n\n        test_s += model.predict_proba(X_test)[:, 1] / skf.n_splits\n\n        del model\n        gc.collect()\n\n    auc_s = roc_auc_score(y, oof_s)\n    xgb_oof_aucs.append(auc_s)\n\n    oof_xgb += oof_s / len(xgb_seeds)\n    test_xgb += test_s / len(xgb_seeds)\n\n    print(f\"XGB Seed {s} | OOF AUC: {auc_s:.6f}\")\n\nprint(\"XGB Mean OOF AUC:\", float(np.mean(xgb_oof_aucs)))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```Train multi-seed CatBoost (OOF + test probs)```","metadata":{}},{"cell_type":"code","source":"oof_cat = np.zeros(len(train_df), dtype=np.float32)\ntest_cat = np.zeros(len(test_df), dtype=np.float32)\ncat_oof_aucs = []\n\nfor s in cat_seeds:\n    oof_s = np.zeros(len(train_df), dtype=np.float32)\n    test_s = np.zeros(len(test_df), dtype=np.float32)\n\n    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n        X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n        X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n\n        model = CatBoostClassifier(**cat_params, random_seed=s + fold)\n        model.fit(\n            X_tr, y_tr,\n            eval_set=(X_va, y_va),\n            cat_features=cat_features\n        )\n\n        va_pred = model.predict_proba(X_va)[:, 1]\n        oof_s[va_idx] = va_pred\n\n        test_s += model.predict_proba(X_test)[:, 1] / skf.n_splits\n\n        del model\n        gc.collect()\n\n    auc_s = roc_auc_score(y, oof_s)\n    cat_oof_aucs.append(auc_s)\n\n    oof_cat += oof_s / len(cat_seeds)\n    test_cat += test_s / len(cat_seeds)\n\n    print(f\"CAT Seed {s} | OOF AUC: {auc_s:.6f}\")\n\nprint(\"CAT Mean OOF AUC:\", float(np.mean(cat_oof_aucs)))\nprint(\"CatBoost Std  OOF AUC:\", np.std(cat_oof_aucs))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```optimal bend weight```","metadata":{}},{"cell_type":"code","source":"# Rank-transform OOF predictions\nrank_oof_xgb = rankdata(oof_xgb)\nrank_oof_cat = rankdata(oof_cat)\n\n# Optional: scale ranks to [0, 1] (not required for AUC, but nice)\nrank_oof_xgb = (rank_oof_xgb - rank_oof_xgb.min()) / (rank_oof_xgb.max() - rank_oof_xgb.min())\nrank_oof_cat = (rank_oof_cat - rank_oof_cat.min()) / (rank_oof_cat.max() - rank_oof_cat.min())\n\nweights = np.arange(0.0, 1.01, 0.05)\n\nbest = {\"auc\": -1.0, \"w_xgb\": 0.5}\n\nfor w in weights:\n    oof_blend_rank = w * rank_oof_xgb + (1.0 - w) * rank_oof_cat\n    auc = roc_auc_score(y, oof_blend_rank)\n    if auc > best[\"auc\"]:\n        best.update({\"auc\": auc, \"w_xgb\": w})\n\nw0 = best[\"w_xgb\"]\nfine_weights = np.arange(max(0.0, w0 - 0.10), min(1.0, w0 + 0.10) + 1e-9, 0.01)\n\nbest_fine = {\"auc\": -1.0, \"w_xgb\": w0}\n\nfor w in fine_weights:\n    oof_blend_rank = w * rank_oof_xgb + (1.0 - w) * rank_oof_cat\n    auc = roc_auc_score(y, oof_blend_rank)\n    if auc > best_fine[\"auc\"]:\n        best_fine.update({\"auc\": auc, \"w_xgb\": w})\n\nw_best = best_fine[\"w_xgb\"]\n\nprint(\"Best blend OOF AUC (rank):\", best_fine[\"auc\"])\nprint(\"Best w_xgb:\", w_best, \"| w_cat:\", 1.0 - w_best)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rank_test_xgb = rankdata(test_xgb)\nrank_test_cat = rankdata(test_cat)\n\nrank_test_xgb = (rank_test_xgb - rank_test_xgb.min()) / (rank_test_xgb.max() - rank_test_xgb.min())\nrank_test_cat = (rank_test_cat - rank_test_cat.min()) / (rank_test_cat.max() - rank_test_cat.min())\n\nfinal_test_probs = w_best * rank_test_xgb + (1.0 - w_best) * rank_test_cat","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```create submission```","metadata":{}},{"cell_type":"code","source":"if os.path.exists(\"submission.csv\"):\n    os.remove(\"submission.csv\")\n    \nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"Heart Disease\": final_test_probs  # probabilities\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved new submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}